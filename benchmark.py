#!/usr/bin/env python3
"""
ChatterBox TTS API Benchmark Script

This script tests the performance and scalability of the ChatterBox TTS API
by sending concurrent requests with varying text lengths and measuring
key performance metrics.
"""

import asyncio
import aiohttp
import time
import json
import statistics
import argparse
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional
import random
import sys
from pathlib import Path
import csv
import os
import hashlib

@dataclass
class RequestMetrics:
    """Metrics for a single request"""
    concurrent_requests: int
    text_length: int
    text_content: str
    start_time: float
    first_chunk_time: Optional[float]
    end_time: float
    total_time: float
    time_to_first_chunk: Optional[float]
    success: bool
    error_message: Optional[str]
    audio_size_bytes: int
    status_code: Optional[int]
    chunks_received: int
    audio_file_path: Optional[str] = None

@dataclass
class ConcurrencyMetrics:
    """Aggregated metrics for a concurrency level"""
    concurrent_requests: int
    total_requests: int
    successful_requests: int
    failed_requests: int
    avg_total_time: float
    avg_time_to_first_chunk: float
    min_total_time: float
    max_total_time: float
    median_total_time: float
    p95_total_time: float
    avg_audio_size: float
    requests_per_second: float
    error_rate: float
    avg_text_length: int

class ChatterBoxBenchmark:
    def __init__(self, base_url: str = "http://localhost:6401"):
        self.base_url = base_url.rstrip('/')
        self.endpoint = f"{self.base_url}/stream/audio/speech"
        
        # Test texts with different lengths
        self.test_texts = [
            # ŸÜÿµŸàÿµ ŸÇÿµŸäÿ±ÿ© (10-30 ŸÉŸÑŸÖÿ©)
            "ŸÖÿ±ÿ≠ÿ®Ÿãÿß ÿ®ÿßŸÑÿπÿßŸÑŸÖÿå Ÿáÿ∞ÿß ÿßÿÆÿ™ÿ®ÿßÿ± ÿ®ÿ≥Ÿäÿ∑.",
            "ÿßŸÑÿ´ÿπŸÑÿ® ÿßŸÑÿ≥ÿ±Ÿäÿπ ŸäŸÇŸÅÿ≤ ŸÅŸàŸÇ ÿßŸÑŸÉŸÑÿ® ÿßŸÑŸÉÿ≥ŸàŸÑ.",
            "ÿ£ÿÆÿ™ÿ®ÿ± ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑŸÜÿµ ÿ•ŸÑŸâ ŸÉŸÑÿßŸÖ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ¨ŸÖŸÑ ŸÇÿµŸäÿ±ÿ©.",

            # ŸÜÿµŸàÿµ ŸÖÿ™Ÿàÿ≥ÿ∑ÿ© (50-100 ŸÉŸÑŸÖÿ©)
            "Ÿáÿ∞ÿß ŸÜÿµ ŸÖÿ™Ÿàÿ≥ÿ∑ ÿßŸÑÿ∑ŸàŸÑ ÿµŸèŸÖŸÖ ŸÑÿßÿÆÿ™ÿ®ÿßÿ± ÿ£ÿØÿßÿ° ŸÜÿ∏ÿßŸÖ ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑŸÜÿµ ÿ•ŸÑŸâ ŸÉŸÑÿßŸÖ ÿ™ÿ≠ÿ™ ÿ∏ÿ±ŸàŸÅ ŸÖÿπÿ™ÿØŸÑÿ©. Ÿäÿ¨ÿ® ÿ£ŸÜ Ÿäÿ™ÿπÿßŸÖŸÑ ÿßŸÑŸÜÿ∏ÿßŸÖ ŸÖÿπ ÿ∞ŸÑŸÉ ÿ®ÿ¥ŸÉŸÑ ÿ¨ŸäÿØ ŸÖÿπ ÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿ¨ŸàÿØÿ© ÿµŸàÿ™ ŸÖŸÇÿ®ŸàŸÑÿ© Ÿàÿ≤ŸÖŸÜ ÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© ŸÖÿπŸÇŸàŸÑ.",
            "ŸÑŸÇÿØ ÿ∫ŸäŸëÿ±ÿ™ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ÿ¨ŸàÿßŸÜÿ® ÿ≠Ÿäÿßÿ™ŸÜÿß ÿßŸÑŸäŸàŸÖŸäÿ©ÿå ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿßÿπÿØÿßÿ™ ÿßŸÑÿµŸàÿ™Ÿäÿ© ÿ•ŸÑŸâ ÿ£ŸÜÿ∏ŸÖÿ© ÿÆÿØŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ° ÿßŸÑÿ¢ŸÑŸäÿ©. Ÿàÿ™ŸèÿπÿØ ÿ™ŸÇŸÜŸäÿ© ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑŸÜÿµ ÿ•ŸÑŸâ ŸÉŸÑÿßŸÖ ÿ£ÿØÿßÿ© ÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÑÿ¨ÿπŸÑ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÖÿ™ÿßÿ≠ÿ© ŸÑŸÑÿ¨ŸÖŸäÿπÿå ÿ®ŸÖÿß ŸÅŸä ÿ∞ŸÑŸÉ ÿ∞ŸàŸä ÿßŸÑÿ•ÿπÿßŸÇÿßÿ™ ÿßŸÑÿ®ÿµÿ±Ÿäÿ© ÿ£Ÿà ÿµÿπŸàÿ®ÿßÿ™ ÿßŸÑŸÇÿ±ÿßÿ°ÿ©.",
            "ÿßŸÑÿ∑ŸÇÿ≥ ÿßŸÑŸäŸàŸÖ ÿ±ÿßÿ¶ÿπ ŸÑŸÑÿ∫ÿßŸäÿ©ÿå ÿßŸÑÿ≥ŸÖÿßÿ° ÿµÿßŸÅŸäÿ© ÿ≤ÿ±ŸÇÿßÿ° ŸàÿßŸÑŸÜÿ≥ŸäŸÖ ÿπŸÑŸäŸÑ. ÿ•ŸÜŸá ŸäŸàŸÖ ŸÖÿ´ÿßŸÑŸä ŸÑŸÑÿ£ŸÜÿ¥ÿ∑ÿ© ÿßŸÑÿÆÿßÿ±ÿ¨Ÿäÿ© ŸÖÿ´ŸÑ ÿßŸÑÿ™ŸÜÿ≤Ÿáÿå ÿ£Ÿà ÿßŸÑŸÇŸäÿßŸÖ ÿ®ŸÜÿ≤Ÿáÿ©ÿå ÿ£Ÿà ŸÖÿ¨ÿ±ÿØ ÿßŸÑÿ≥Ÿäÿ± ÿ®ŸáÿØŸàÿ° ŸÅŸä ÿßŸÑÿ≠ÿØŸäŸÇÿ© ŸàÿßŸÑÿßÿ≥ÿ™ŸÖÿ™ÿßÿπ ÿ®ÿßŸÑŸáŸàÿßÿ° ÿßŸÑŸÜŸÇŸä Ÿàÿ£ÿ¥ÿπÿ© ÿßŸÑÿ¥ŸÖÿ≥.",

            # ŸÜÿµŸàÿµ ÿ∑ŸàŸäŸÑÿ© (150-250 ŸÉŸÑŸÖÿ©)
            "ŸÅŸä ÿßŸÑŸÖÿ¥ŸáÿØ ÿ≥ÿ±Ÿäÿπ ÿßŸÑÿ™ÿ∑Ÿàÿ± ŸÑŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä Ÿàÿ™ÿπŸÑŸÖ ÿßŸÑÿ¢ŸÑÿ©ÿå ÿ®ÿ±ÿ≤ ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑŸÜÿµ ÿ•ŸÑŸâ ŸÉŸÑÿßŸÖ ŸÉÿ£ÿ≠ÿØ ÿ£ŸÉÿ´ÿ± ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿπŸÖŸÑŸäÿ© ŸàÿßŸÑŸÖŸÜÿ™ÿ¥ÿ±ÿ©. ÿ™ÿπÿ™ŸÖÿØ ÿ£ŸÜÿ∏ŸÖÿ© TTS ÿßŸÑÿ≠ÿØŸäÿ´ÿ© ÿπŸÑŸâ ÿßŸÑÿ¥ÿ®ŸÉÿßÿ™ ÿßŸÑÿπÿµÿ®Ÿäÿ© ÿßŸÑÿπŸÖŸäŸÇÿ©ÿå ÿÆÿµŸàÿµŸãÿß ÿ®ŸÜŸäÿ© ÿßŸÑŸÖÿ≠ŸàŸÑÿßÿ™ÿå ŸÑÿ™ŸàŸÑŸäÿØ ÿµŸàÿ™ ÿ∑ÿ®ŸäÿπŸä ŸàŸÖÿπÿ®ÿ± Ÿäÿ≠ÿßŸÉŸä ÿ®ÿ¥ŸÉŸÑ ŸÉÿ®Ÿäÿ± ÿßŸÑÿ™ŸÜÿ∫ŸäŸÖ ŸàÿßŸÑÿ•ŸäŸÇÿßÿπ ŸàÿßŸÑÿ™ÿπÿ®Ÿäÿ± ÿßŸÑÿπÿßÿ∑ŸÅŸä ÿßŸÑÿ®ÿ¥ÿ±Ÿä. ŸàŸÇÿØ Ÿàÿ¨ÿØÿ™ Ÿáÿ∞Ÿá ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸÖÿ™ÿπÿØÿØÿ© ŸÖŸÜ ÿ£ÿØŸàÿßÿ™ ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÑÿ∞ŸàŸä ÿßŸÑÿ•ÿπÿßŸÇÿßÿ™ ÿßŸÑÿ®ÿµÿ±Ÿäÿ© ÿ•ŸÑŸâ ÿßŸÑŸÖÿ≥ÿßÿπÿØÿßÿ™ ÿßŸÑÿµŸàÿ™Ÿäÿ©ÿå Ÿàÿ±ŸàÿßŸäÿ© ÿßŸÑŸÉÿ™ÿ® ÿßŸÑÿµŸàÿ™Ÿäÿ©ÿå Ÿàÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ±ÿØ ÿßŸÑÿ¢ŸÑŸä ÿßŸÑÿ™ŸÅÿßÿπŸÑŸäÿ© ŸÅŸä ÿ®Ÿäÿ¶ÿßÿ™ ÿÆÿØŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ°.",
            "ÿ•ŸÜ ÿ™ÿ∑ŸàŸäÿ± ÿ£ŸÜÿ∏ŸÖÿ© ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑŸÜÿµ ÿ•ŸÑŸâ ŸÉŸÑÿßŸÖ ŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÑÿ∫ÿßÿ™ ŸäŸÖÿ´ŸÑ ÿ™ÿ≠ÿØŸäÿßÿ™ ŸàŸÅÿ±ÿµŸãÿß ŸÅÿ±ŸäÿØÿ© ŸÅŸä ŸÖÿ¨ÿßŸÑ ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ©. ŸÅÿπŸÑŸâ ÿπŸÉÿ≥ ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ÿ£ÿ≠ÿßÿØŸäÿ© ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿ™Ÿä ÿ™ÿ±ŸÉÿ≤ ÿπŸÑŸâ ÿ•ÿ™ŸÇÿßŸÜ ŸÑÿ∫ÿ© Ÿàÿßÿ≠ÿØÿ©ÿå Ÿäÿ¨ÿ® ÿπŸÑŸâ ÿßŸÑÿ£ŸÜÿ∏ŸÖÿ© ŸÖÿ™ÿπÿØÿØÿ© ÿßŸÑŸÑÿ∫ÿßÿ™ ÿßŸÑÿ™ÿπÿßŸÖŸÑ ŸÖÿπ ÿßŸÑÿßÿÆÿ™ŸÑÿßŸÅÿßÿ™ ÿßŸÑÿµŸàÿ™Ÿäÿ© ŸàÿßŸÑÿ•ŸäŸÇÿßÿπŸäÿ© ŸàÿßŸÑÿ´ŸÇÿßŸÅŸäÿ© ÿ®ŸäŸÜ ÿßŸÑŸÑÿ∫ÿßÿ™ ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ© ŸÖÿπ ÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿ¨ŸàÿØÿ© ÿ∑ÿ®ŸäÿπŸäÿ© ŸÖÿ™ÿ≥ŸÇÿ©. ŸàŸäÿ™ÿ∑ŸÑÿ® ÿ∞ŸÑŸÉ ŸÜŸÖÿßÿ∞ÿ¨ ŸÖÿ™ŸÇÿØŸÖÿ© ŸÇÿßÿØÿ±ÿ© ÿπŸÑŸâ ŸÅŸáŸÖ Ÿàÿ™ŸàŸÑŸäÿØ ÿßŸÑŸÅÿ±ŸàŸÇ ÿßŸÑÿØŸÇŸäŸÇÿ© ŸÅŸä ÿßŸÑŸÜÿ∑ŸÇ Ÿàÿ£ŸÜŸÖÿßÿ∑ ÿßŸÑÿ∂ÿ∫ÿ∑ ŸàÿßŸÑÿ™ŸÜÿ∫ŸäŸÖ ÿßŸÑÿ™Ÿä ÿ™ŸÖŸäÿ≤ ŸÉŸÑ ŸÑÿ∫ÿ©ÿå ŸÖŸÖÿß Ÿäÿ¨ÿπŸÑŸáÿß ŸÖÿ¨ÿßŸÑŸãÿß ŸÖÿπŸÇÿØŸãÿß ŸÑŸÉŸÜŸá ŸÖÿ´ŸÖÿ± ŸÅŸä ÿßŸÑÿ®ÿ≠ÿ´ ŸàÿßŸÑÿ™ÿ∑ŸàŸäÿ±.",
            "ŸäŸÖÿ´ŸÑ ÿ™ÿ∫ŸäŸëÿ± ÿßŸÑŸÖŸÜÿßÿÆ ÿ£ÿ≠ÿØ ÿ£ŸÉÿ´ÿ± ÿßŸÑÿ™ÿ≠ÿØŸäÿßÿ™ ÿ•ŸÑÿ≠ÿßÿ≠Ÿãÿß ŸÅŸä ÿπÿµÿ±ŸÜÿßÿå ÿ≠Ÿäÿ´ Ÿäÿ§ÿ´ÿ± ÿπŸÑŸâ ÿßŸÑŸÜÿ∏ŸÖ ÿßŸÑÿ®Ÿäÿ¶Ÿäÿ© Ÿàÿ£ŸÜŸÖÿßÿ∑ ÿßŸÑÿ∑ŸÇÿ≥ ŸàÿßŸÑŸÖÿ¨ÿ™ŸÖÿπÿßÿ™ ÿßŸÑÿ®ÿ¥ÿ±Ÿäÿ© ŸÅŸä ÿ¨ŸÖŸäÿπ ÿ£ŸÜÿ≠ÿßÿ° ÿßŸÑÿπÿßŸÑŸÖ. Ÿàÿ™ÿ¥Ÿäÿ± ÿßŸÑÿ™ŸàÿßŸÅŸÇÿßÿ™ ÿßŸÑÿπŸÑŸÖŸäÿ© ÿ®Ÿàÿ∂Ÿàÿ≠ ÿ•ŸÑŸâ ÿ£ŸÜ ÿßŸÑÿ£ŸÜÿ¥ÿ∑ÿ© ÿßŸÑÿ®ÿ¥ÿ±Ÿäÿ©ÿå ŸàÿÆÿßÿµÿ© ÿßŸÜÿ®ÿπÿßÿ´ ÿßŸÑÿ∫ÿßÿ≤ÿßÿ™ ÿßŸÑÿØŸÅŸäÿ¶ÿ© ÿßŸÑŸÜÿßÿ™ÿ¨ÿ© ÿπŸÜ ÿßÿ≠ÿ™ÿ±ÿßŸÇ ÿßŸÑŸàŸÇŸàÿØ ÿßŸÑÿ£ÿ≠ŸÅŸàÿ±Ÿä Ÿàÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ∫ÿßÿ®ÿßÿ™ ŸàÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑÿµŸÜÿßÿπŸäÿ©ÿå ŸáŸä ÿßŸÑŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿä ŸÑŸÑÿ™ÿ∫ŸäŸëÿ± ÿßŸÑŸÖŸÜÿßÿÆŸä ÿßŸÑÿ≠ÿßŸÑŸä. ŸÅŸÇÿØ ÿ£ÿØÿ™ ÿØÿ±ÿ¨ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±ÿ© ÿßŸÑÿπÿßŸÑŸÖŸäÿ© ÿßŸÑŸÖÿ±ÿ™ŸÅÿπÿ© ÿ•ŸÑŸâ ÿ∞Ÿàÿ®ÿßŸÜ ÿßŸÑÿ¨ŸÑŸäÿØÿå Ÿàÿßÿ±ÿ™ŸÅÿßÿπ ŸÖÿ≥ÿ™ŸàŸäÿßÿ™ ÿßŸÑÿ®ÿ≠ÿßÿ±ÿå Ÿàÿ™ÿ≤ÿßŸäÿØ ÿßŸÑÿ∏ŸàÿßŸáÿ± ÿßŸÑÿ¨ŸàŸäÿ© ÿßŸÑŸÖÿ™ÿ∑ÿ±ŸÅÿ©ÿå Ÿàÿ™ÿ≠ŸàŸÑÿßÿ™ ŸÅŸä ÿ£ŸÜŸÖÿßÿ∑ Ÿáÿ∑ŸàŸÑ ÿßŸÑÿ£ŸÖÿ∑ÿßÿ± ÿ™ŸáÿØÿØ ÿßŸÑÿ≤ÿ±ÿßÿπÿ© ŸàÿßŸÑÿ£ŸÖŸÜ ÿßŸÑŸÖÿßÿ¶Ÿä ŸàÿßŸÑÿ™ŸÜŸàÿπ ÿßŸÑÿ®ŸäŸàŸÑŸàÿ¨Ÿä ÿ≠ŸàŸÑ ÿßŸÑÿπÿßŸÑŸÖ.",

            # ŸÜÿµŸàÿµ ÿ∑ŸàŸäŸÑÿ© ÿ¨ÿØŸãÿß (300+ ŸÉŸÑŸÖÿ©)
            "Ÿäÿ™ŸÖŸäÿ≤ ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ≠ÿ∂ÿßÿ±ÿ© ÿßŸÑÿ•ŸÜÿ≥ÿßŸÜŸäÿ© ÿ®ÿßÿ®ÿ™ŸÉÿßÿ±ÿßÿ™ ŸÖÿØŸáÿ¥ÿ© ÿ∫ŸäŸëÿ±ÿ™ ÿ∑ÿ±ŸÇ ÿπŸäÿ¥ŸÜÿß ŸàÿπŸÖŸÑŸÜÿß Ÿàÿ™ŸàÿßÿµŸÑŸÜÿß ŸÖÿπ ÿ®ÿπÿ∂ŸÜÿß ÿßŸÑÿ®ÿπÿ∂. ŸÖŸÜ ÿßÿÆÿ™ÿ±ÿßÿπ ÿßŸÑÿπÿ¨ŸÑÿ© Ÿàÿ™ÿ∑ŸàŸäÿ± ÿßŸÑŸÉÿ™ÿßÿ®ÿ© ÿ•ŸÑŸâ ÿßŸÑÿ´Ÿàÿ±ÿ© ÿßŸÑÿµŸÜÿßÿπŸäÿ© ŸàÿßŸÑÿπÿµÿ± ÿßŸÑÿ±ŸÇŸÖŸäÿå ŸÉŸÑ ÿ•ŸÜÿ¨ÿßÿ≤ ÿ®ŸÜŸâ ÿπŸÑŸâ ŸÖÿß ÿ≥ÿ®ŸÇŸá ŸÑŸäÿ§ÿ≥ÿ≥ ŸÖÿ¨ÿ™ŸÖÿπÿßÿ™ ÿ£ŸÉÿ´ÿ± ÿ™ÿ∑Ÿàÿ±Ÿãÿß. ŸÑŸÇÿØ ÿ¨ÿπŸÑÿ™ ÿßŸÑÿ∑ÿ®ÿßÿπÿ© ÿßŸÑŸÖÿπÿ±ŸÅÿ© ŸÖÿ™ÿßÿ≠ÿ© ŸÑŸÑÿ¨ŸÖŸäÿπÿå Ÿàÿ≠ÿ±ŸëŸÉ ÿßŸÑŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ®ÿÆÿßÿ±Ÿä ÿπÿ¨ŸÑÿ© ÿßŸÑÿ™ÿµŸÜŸäÿπÿå Ÿàÿ£ÿ∂ÿßÿ°ÿ™ ÿßŸÑŸÉŸáÿ±ÿ®ÿßÿ° ÿπÿßŸÑŸÖŸÜÿßÿå Ÿàÿ±ÿ®ÿ∑ŸÜÿß ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿπÿßŸÑŸÖŸäŸãÿß ÿ®ÿ∑ÿ±ŸÇ ŸÑŸÖ ŸäŸÉŸÜ ÿ£ÿ≥ŸÑÿßŸÅŸÜÿß ŸÑŸäÿ™ÿµŸàÿ±ŸàŸáÿß. ŸàÿßŸÑŸäŸàŸÖ ŸÜŸÇŸÅ ÿπŸÑŸâ ÿ£ÿπÿ™ÿßÿ® ŸÅÿ™ÿ±ÿ© ÿ´Ÿàÿ±Ÿäÿ© ÿ¨ÿØŸäÿØÿ©ÿå ÿ≠Ÿäÿ´ ŸäÿπÿØŸÜÿß ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸàÿßŸÑÿ≠Ÿàÿ≥ÿ®ÿ© ÿßŸÑŸÉŸÖŸäÿ© ŸàÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß ÿßŸÑÿ≠ŸäŸàŸäÿ© ŸàÿßŸÑÿ∑ÿßŸÇÿ© ÿßŸÑŸÖÿ™ÿ¨ÿØÿØÿ© ÿ®ÿ•ÿπÿßÿØÿ© ÿ™ÿ¥ŸÉŸäŸÑ ŸÖÿ≥ÿ™ŸÇÿ®ŸÑŸÜÿß ÿ®ÿ∑ÿ±ŸÇ ÿπŸÖŸäŸÇÿ© Ÿàÿ∫Ÿäÿ± ŸÖÿ≥ÿ®ŸàŸÇÿ©. Ÿáÿ∞Ÿá ÿßŸÑÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑŸÜÿßÿ¥ÿ¶ÿ© ÿ™ÿ≠ŸÖŸÑ ÿ•ŸÖŸÉÿßŸÜŸäÿßÿ™ Ÿáÿßÿ¶ŸÑÿ© ŸÑÿ≠ŸÑ ÿ®ÿπÿ∂ ÿ£ÿπÿ∏ŸÖ ÿ™ÿ≠ÿØŸäÿßÿ™ ÿßŸÑÿ®ÿ¥ÿ±Ÿäÿ©ÿå ŸÖŸÜ ÿ™ÿ∫ŸäŸëÿ± ÿßŸÑŸÖŸÜÿßÿÆ ŸàÿßŸÑÿ£ŸÖÿ±ÿßÿ∂ ÿ•ŸÑŸâ ÿßŸÑŸÅŸÇÿ± ŸàÿπÿØŸÖ ÿßŸÑŸÖÿ≥ÿßŸàÿßÿ©ÿå ŸÑŸÉŸÜŸáÿß ÿ™ÿ´Ÿäÿ± ÿ£Ÿäÿ∂Ÿãÿß ÿ£ÿ≥ÿ¶ŸÑÿ© ŸáÿßŸÖÿ© ÿ≠ŸàŸÑ ÿßŸÑÿ£ÿÆŸÑÿßŸÇŸäÿßÿ™ ŸàÿßŸÑÿÆÿµŸàÿµŸäÿ© ŸàÿßŸÑÿπŸÖŸÑ Ÿàÿ≠ÿ™Ÿâ ÿ∑ÿ®Ÿäÿπÿ© ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑÿ•ŸÜÿ≥ÿßŸÜŸäÿ© ŸÅŸä ÿπÿßŸÑŸÖ Ÿäÿ≤ÿØÿßÿØ ÿ£ÿ™ŸÖÿ™ÿ©. Ÿàÿ®ŸäŸÜŸÖÿß ŸÜÿ™ŸÜŸÇŸÑ ŸÅŸä Ÿáÿ∞ÿß ÿßŸÑŸÖÿ¥ŸáÿØ ÿßŸÑŸÖÿπŸÇÿØ ŸÖŸÜ ÿßŸÑÿ™ŸÇÿØŸëŸÖ ÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿå Ÿäÿµÿ®ÿ≠ ŸÖŸÜ ÿßŸÑÿ∂ÿ±Ÿàÿ±Ÿä ÿ£ŸÜ ŸÜŸàÿßÿ¨Ÿá ÿßŸÑÿßÿ®ÿ™ŸÉÿßÿ± ÿ®ÿ≠ŸÉŸÖÿ©ÿå ŸÖÿπ ÿ∂ŸÖÿßŸÜ ÿ£ŸÜ Ÿäÿ™ŸÖ ÿ™ŸÇÿßÿ≥ŸÖ ÿßŸÑŸÅŸàÿßÿ¶ÿØ ÿπŸÑŸâ ŸÜÿ∑ÿßŸÇ Ÿàÿßÿ≥ÿπÿå Ÿàÿ£ŸÜ ŸÜÿ≠ÿßŸÅÿ∏ ŸÅŸä ÿßŸÑŸàŸÇÿ™ ŸÜŸÅÿ≥Ÿá ÿπŸÑŸâ ÿßŸÑŸÇŸäŸÖ ŸàÿßŸÑŸÖÿ®ÿßÿØÿ¶ ÿßŸÑÿ™Ÿä ÿ™Ÿèÿπÿ±ŸëŸÅ ÿ•ŸÜÿ≥ÿßŸÜŸäÿ™ŸÜÿß."
        ]
        
    async def make_request(self, session: aiohttp.ClientSession, text: str, concurrent_count: int) -> RequestMetrics:
        """Make a single request and measure metrics"""
        # Create unique identifier for this request
        text_hash = hashlib.md5(text.encode()).hexdigest()[:8]
        timestamp = int(time.time() * 1000)  # milliseconds
        request_id = f"{concurrent_count}x_{timestamp}_{text_hash}"
        
        print(f"üöÄ Starting request {request_id} - Text: '{text[:50]}{'...' if len(text) > 50 else ''}' (Concurrent: {concurrent_count})")
        
        payload = {
            "input": text,
            "language_id": "ar",
            "speed": 1.0,
            "exaggeration": 0.7,
            "cfg_weight": 0.3,
            "temperature": 0.8,
            "chunk_size": 25,
            "output_sample_rate": 8000
        }
        
        # Create output directory and file path
        os.makedirs("storage", exist_ok=True)
        audio_file_path = f"storage/audio_{request_id}.wav"
        
        metrics = RequestMetrics(
            concurrent_requests=concurrent_count,
            text_length=len(text.split()),
            text_content=text[:100] + "..." if len(text) > 100 else text,
            start_time=time.time(),
            first_chunk_time=None,
            end_time=0,
            total_time=0,
            time_to_first_chunk=None,
            success=False,
            error_message=None,
            audio_size_bytes=0,
            status_code=None,
            chunks_received=0,
            audio_file_path=audio_file_path
        )
        
        try:
            async with session.post(self.endpoint, json=payload) as response:
                metrics.status_code = response.status
                
                if response.status != 200:
                    metrics.error_message = f"HTTP {response.status}: {await response.text()}"
                    metrics.end_time = time.time()
                    metrics.total_time = metrics.end_time - metrics.start_time
                    print(f"‚ùå Request {request_id} failed with status {response.status}")
                    return metrics
                
                # Read streaming response and save to file
                first_chunk = True
                print(f"üì° Request {request_id} - Receiving audio chunks...")
                
                with open(audio_file_path, 'wb') as audio_file:
                    async for chunk in response.content.iter_chunked(1024):
                        if first_chunk:
                            metrics.first_chunk_time = time.time()
                            metrics.time_to_first_chunk = metrics.first_chunk_time - metrics.start_time
                            print(f"‚ö° Request {request_id} - First chunk received in {metrics.time_to_first_chunk:.2f}s")
                            first_chunk = False
                        
                        audio_file.write(chunk)
                        metrics.audio_size_bytes += len(chunk)
                        metrics.chunks_received += 1
                
                metrics.success = True
                print(f"‚úÖ Request {request_id} completed - Audio saved to {audio_file_path} ({metrics.audio_size_bytes} bytes, {metrics.chunks_received} chunks)")
                
        except asyncio.TimeoutError:
            metrics.error_message = "Request timeout"
            print(f"‚è∞ Request {request_id} timed out after 120s")
        except aiohttp.ClientError as e:
            metrics.error_message = f"Client error: {str(e)}"
            print(f"‚ùå Request {request_id} client error: {str(e)}")
        except Exception as e:
            metrics.error_message = f"Unexpected error: {str(e)}"
            print(f"üí• Request {request_id} unexpected error: {str(e)}")
        finally:
            metrics.end_time = time.time()
            metrics.total_time = metrics.end_time - metrics.start_time
            
        return metrics
    
    async def run_concurrency_test(self, concurrent_requests: int, requests_per_level: int = 10) -> List[RequestMetrics]:
        """Run benchmark for a specific concurrency level"""
        print(f"\n{'='*60}")
        print(f"Testing {concurrent_requests} concurrent request{'s' if concurrent_requests > 1 else ''}")
        print(f"{'='*60}")
        
        # Create random selection of texts for this test
        selected_texts = random.choices(self.test_texts, k=requests_per_level)
        
        timeout = aiohttp.ClientTimeout(total=120)  # 2 minute timeout
        connector = aiohttp.TCPConnector(limit=100, limit_per_host=50)
        
        async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
            tasks = []
            
            # Create batches of concurrent requests
            for i in range(0, requests_per_level, concurrent_requests):
                batch_size = min(concurrent_requests, requests_per_level - i)
                batch_texts = selected_texts[i:i + batch_size]
                
                # Create tasks for this batch
                batch_tasks = [
                    self.make_request(session, text, concurrent_requests)
                    for text in batch_texts
                ]
                
                print(f"Launching batch of {len(batch_tasks)} requests...")
                start_time = time.time()
                
                # Execute batch concurrently
                batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
                
                batch_time = time.time() - start_time
                print(f"Batch completed in {batch_time:.2f}s")
                
                # Process results and handle exceptions
                for result in batch_results:
                    if isinstance(result, Exception):
                        # Create error metrics for exceptions
                        error_metrics = RequestMetrics(
                            concurrent_requests=concurrent_requests,
                            text_length=0,
                            text_content="Error occurred",
                            start_time=start_time,
                            first_chunk_time=None,
                            end_time=time.time(),
                            total_time=batch_time,
                            time_to_first_chunk=None,
                            success=False,
                            error_message=str(result),
                            audio_size_bytes=0,
                            status_code=None,
                            chunks_received=0,
                            audio_file_path=None
                        )
                        tasks.append(error_metrics)
                    else:
                        tasks.append(result)
                
                # Brief pause between batches to avoid overwhelming the server
                if i + batch_size < requests_per_level:
                    await asyncio.sleep(1)
        
        return tasks
    
    def calculate_metrics(self, results: List[RequestMetrics]) -> Optional[ConcurrencyMetrics]:
        """Calculate aggregated metrics for a concurrency level"""
        if not results:
            return None
            
        successful_results = [r for r in results if r.success]
        failed_results = [r for r in results if not r.success]
        
        total_times = [r.total_time for r in results]
        first_chunk_times = [r.time_to_first_chunk for r in successful_results if r.time_to_first_chunk is not None]
        audio_sizes = [r.audio_size_bytes for r in successful_results]
        text_lengths = [r.text_length for r in results if r.text_length > 0]
        
        # Calculate percentiles
        total_times_sorted = sorted(total_times)
        p95_index = int(0.95 * len(total_times_sorted))
        p95_time = total_times_sorted[p95_index] if total_times_sorted else 0
        
        return ConcurrencyMetrics(
            concurrent_requests=results[0].concurrent_requests,
            total_requests=len(results),
            successful_requests=len(successful_results),
            failed_requests=len(failed_results),
            avg_total_time=statistics.mean(total_times) if total_times else 0,
            avg_time_to_first_chunk=statistics.mean(first_chunk_times) if first_chunk_times else 0,
            min_total_time=min(total_times) if total_times else 0,
            max_total_time=max(total_times) if total_times else 0,
            median_total_time=statistics.median(total_times) if total_times else 0,
            p95_total_time=p95_time,
            avg_audio_size=statistics.mean(audio_sizes) if audio_sizes else 0,
            requests_per_second=len(successful_results) / statistics.mean(total_times) if total_times and statistics.mean(total_times) > 0 else 0,
            error_rate=(len(failed_results) / len(results)) * 100 if results else 0,
            avg_text_length=int(statistics.mean(text_lengths)) if text_lengths else 0
        )
    
    def print_results(self, metrics: ConcurrencyMetrics, detailed_results: List[RequestMetrics]):
        """Print benchmark results"""
        print(f"\nüìä Results for {metrics.concurrent_requests} concurrent requests:")
        print(f"   Total Requests: {metrics.total_requests}")
        print(f"   ‚úÖ Successful: {metrics.successful_requests}")
        print(f"   ‚ùå Failed: {metrics.failed_requests}")
        print(f"   üö® Error Rate: {metrics.error_rate:.1f}%")
        print(f"   üìù Avg Text Length: {metrics.avg_text_length:.0f} words")
        
        print(f"\n‚è±Ô∏è  Timing Metrics:")
        print(f"   Avg Total Time: {metrics.avg_total_time:.2f}s")
        print(f"   Avg Time to First Chunk: {metrics.avg_time_to_first_chunk:.2f}s")
        print(f"   Min/Max/Median: {metrics.min_total_time:.2f}s / {metrics.max_total_time:.2f}s / {metrics.median_total_time:.2f}s")
        print(f"   95th Percentile: {metrics.p95_total_time:.2f}s")
        
        print(f"\nüîä Audio Metrics:")
        print(f"   Avg Audio Size: {metrics.avg_audio_size/1024:.1f} KB")
        print(f"   Requests/Second: {metrics.requests_per_second:.2f}")
        
        # Count saved audio files
        saved_audio_files = len([r for r in detailed_results if r.success and r.audio_file_path])
        print(f"   üíæ Audio Files Saved: {saved_audio_files}")
        if saved_audio_files > 0:
            print(f"   üìÅ Audio Directory: storage/")
        
        # Show errors if any
        failed_results = [r for r in detailed_results if not r.success]
        if failed_results:
            print(f"\n‚ùå Error Details:")
            error_counts = {}
            for result in failed_results:
                error_type = result.error_message or "Unknown error"
                error_counts[error_type] = error_counts.get(error_type, 0) + 1
            
            for error, count in error_counts.items():
                print(f"   {error}: {count} occurrences")
    
    def save_results_to_csv(self, all_results: List[List[RequestMetrics]], filename: str = "benchmark_results.csv"):
        """Save detailed results to CSV file"""
        print(f"\nüíæ Saving detailed results to {filename}...")
        
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = [
                'concurrent_requests', 'text_length', 'text_content', 'start_time',
                'total_time', 'time_to_first_chunk', 'success', 'error_message',
                'audio_size_bytes', 'status_code', 'chunks_received', 'audio_file_path'
            ]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for results in all_results:
                for result in results:
                    row = asdict(result)
                    # Remove fields that aren't in fieldnames
                    row = {k: v for k, v in row.items() if k in fieldnames}
                    writer.writerow(row)
        
        print(f"‚úÖ Results saved to {filename}")
    
    def save_summary_to_csv(self, summary_metrics: List[ConcurrencyMetrics], filename: str = "benchmark_summary.csv"):
        """Save summary metrics to CSV file"""
        print(f"üíæ Saving summary metrics to {filename}...")
        
        with open(filename, 'w', newline='') as csvfile:
            fieldnames = list(asdict(summary_metrics[0]).keys()) if summary_metrics else []
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for metrics in summary_metrics:
                writer.writerow(asdict(metrics))
        
        print(f"‚úÖ Summary saved to {filename}")
    
    async def run_full_benchmark(self, max_concurrent: int = 32, requests_per_level: int = 10):
        """Run complete benchmark suite"""
        print("üöÄ Starting ChatterBox TTS Benchmark")
        print(f"   Target URL: {self.base_url}")
        print(f"   Max Concurrent Requests: {max_concurrent}")
        print(f"   Requests per Level: {requests_per_level}")
        print(f"   Test Texts: {len(self.test_texts)} different lengths")
        
        concurrency_levels = [2**i for i in range(int(max_concurrent).bit_length()) if 2**i <= max_concurrent]
        if 1 not in concurrency_levels:
            concurrency_levels.insert(0, 1)
        
        print(f"   Concurrency Levels: {concurrency_levels}")
        
        all_results = []
        summary_metrics = []
        
        for concurrent_requests in concurrency_levels:
            try:
                results = await self.run_concurrency_test(concurrent_requests, requests_per_level)
                all_results.append(results)
                
                metrics = self.calculate_metrics(results)
                if metrics:
                    summary_metrics.append(metrics)
                    self.print_results(metrics, results)
                else:
                    print(f"‚ùå No results for {concurrent_requests} concurrent requests")
                    
            except Exception as e:
                print(f"‚ùå Error during {concurrent_requests} concurrent requests: {e}")
                continue
        
        # Print final summary
        print(f"\n{'='*60}")
        print("üìã BENCHMARK SUMMARY")
        print(f"{'='*60}")
        print(f"{'Concurrent':<12} {'Success%':<9} {'Avg Time':<10} {'First Chunk':<12} {'RPS':<8} {'Errors'}")
        print("-" * 60)
        
        for metrics in summary_metrics:
            success_rate = ((metrics.total_requests - metrics.failed_requests) / metrics.total_requests * 100) if metrics.total_requests > 0 else 0
            print(f"{metrics.concurrent_requests:<12} {success_rate:<8.1f}% {metrics.avg_total_time:<9.2f}s {metrics.avg_time_to_first_chunk:<11.2f}s {metrics.requests_per_second:<7.1f} {metrics.failed_requests}")
        
        # Save results
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        self.save_results_to_csv(all_results, f"benchmark_detailed_{timestamp}.csv")
        self.save_summary_to_csv(summary_metrics, f"benchmark_summary_{timestamp}.csv")
        
        print(f"\n‚úÖ Benchmark completed! Check the CSV files for detailed results.")

async def main():
    parser = argparse.ArgumentParser(description="Benchmark ChatterBox TTS API")
    parser.add_argument("--url", default="http://localhost:6401", help="Base URL of the ChatterBox API")
    parser.add_argument("--max-concurrent", type=int, default=32, help="Maximum concurrent requests to test")
    parser.add_argument("--requests-per-level", type=int, default=10, help="Number of requests per concurrency level")
    
    args = parser.parse_args()
    
    benchmark = ChatterBoxBenchmark(base_url=args.url)
    
    try:
        await benchmark.run_full_benchmark(
            max_concurrent=args.max_concurrent,
            requests_per_level=args.requests_per_level
        )
    except KeyboardInterrupt:
        print("\nüõë Benchmark interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Benchmark failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    # Handle event loop for different Python versions
    try:
        asyncio.run(main())
    except RuntimeError:
        # For older Python versions or environments with existing event loops
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(main())
        finally:
            loop.close()
